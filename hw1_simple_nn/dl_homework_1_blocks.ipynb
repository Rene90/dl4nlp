{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from theano import tensor\n",
    "\n",
    "import fuel\n",
    "import h5py\n",
    "from fuel.datasets.hdf5 import H5PYDataset\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme\n",
    "from fuel.transformers import Flatten\n",
    "\n",
    "from blocks.bricks import Linear, Logistic, Softmax\n",
    "from blocks.bricks.cost import CategoricalCrossEntropy\n",
    "from blocks.roles import WEIGHT\n",
    "from blocks.graph import ComputationGraph\n",
    "from blocks.filter import VariableFilter\n",
    "from blocks.initialization import IsotropicGaussian, Constant\n",
    "from blocks.algorithms import GradientDescent, Scale, AdaGrad, Adam\n",
    "from blocks.extensions.monitoring import DataStreamMonitoring\n",
    "from blocks.main_loop import MainLoop\n",
    "from blocks.extensions import FinishAfter, Printing\n",
    "from blocks.extensions.monitoring import TrainingDataMonitoring\n",
    "from blocks_extras.extensions.plot import Plot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8123, 117) (8123, 2)\n"
     ]
    }
   ],
   "source": [
    "header = [\"label\", \"cap-shape\",\"cap-surface\", \"cap-color\", \"bruises\", \"odor\", \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\",\n",
    "\"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\",\n",
    "\"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\",\n",
    "\"habitat\"]\n",
    "\n",
    "def makeOneHot(col):\n",
    "    vals,idx = pd.factorize(col)\n",
    "    res = np.zeros((len(vals),len(idx)))\n",
    "    res[range(len(vals)),vals] = 1\n",
    "    return res\n",
    "\n",
    "def loadData():\n",
    "    df = pd.read_csv(\"./agaricus-lepiota.data\", header=0, names=header)\n",
    "    X = np.hstack([makeOneHot(df[c]) for c in header[1:]])\n",
    "    y = makeOneHot(df[header[0]])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def randomizeData(X,y):\n",
    "    num_instances = X.shape[0]\n",
    "    indices = np.random.permutation(num_instances)\n",
    "    return X[indices,:], y[indices]\n",
    "\n",
    "X, y = loadData()\n",
    "X, y = randomizeData(X,y)\n",
    "\n",
    "\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createH5Dataset(path,X,y):\n",
    "    f = h5py.File(path, mode='w')\n",
    "\n",
    "    split = int(8123*0.8)\n",
    "\n",
    "    features = f.create_dataset('features', (8123, 117), dtype='uint8')\n",
    "    targets = f.create_dataset('targets', (8123, 2), dtype='uint8')\n",
    "\n",
    "    features[...] = X\n",
    "    targets[...] = y\n",
    "\n",
    "    split_dict = {\n",
    "         'train': {'features': (0, splits), 'targets': (0, splits)},\n",
    "         'test':  {'features': (split+1,8123), 'targets': (split,8123)},\n",
    "    }\n",
    "    f.attrs['split'] = H5PYDataset.create_split_array(split_dict)\n",
    "\n",
    "    f.flush()\n",
    "    f.close()\n",
    "\n",
    "#createH5Dataset(\"dataset.hdf5\", X, y)\n",
    "\n",
    "#train_data = H5PYDataset('dataset.hdf5', which_sets=('train',), load_in_memory=True)\n",
    "#test_data  = H5PYDataset('dataset.hdf5', which_sets=('test',), load_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuel.datasets import IndexableDataset\n",
    "\n",
    "def createDataset(X,y):\n",
    "    split = int(X.shape[0]*0.8)\n",
    "    \n",
    "    train = IndexableDataset({\n",
    "        'features': X[:split,:].astype(np.uint8),\n",
    "        'targets': y[:split].astype(np.uint8)\n",
    "    })\n",
    "    test  = IndexableDataset({\n",
    "        'features': X[split:,:].astype(np.uint8),\n",
    "        'targets': y[split:].astype(np.uint8)\n",
    "    })\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train_data, test_data = createDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_stream = Flatten(DataStream.default_stream(\n",
    "     train_data,\n",
    "     iteration_scheme=SequentialScheme(train_data.num_examples, batch_size=50)))\n",
    "\n",
    "data_stream_test = Flatten(DataStream.default_stream(\n",
    "        test_data, \n",
    "        iteration_scheme=SequentialScheme(\n",
    "        test_data.num_examples, batch_size=1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blocks.bricks.cost import MisclassificationRate\n",
    "\n",
    "def makeGraph():\n",
    "    Xs = tensor.matrix(\"features\")\n",
    "    y = tensor.lmatrix('targets')\n",
    "    \n",
    "    h1 = Linear(name='h1', input_dim=117, output_dim=70)\n",
    "    a1 = Logistic().apply(h1.apply(Xs))\n",
    "    h2 = Linear(name='h2', input_dim=70, output_dim=2)\n",
    "    y_hat = Softmax().apply(h2.apply(a1))\n",
    "    \n",
    "    h1.weights_init = h2.weights_init = IsotropicGaussian(0.01)\n",
    "    h1.biases_init = h2.biases_init = Constant(0)\n",
    "    h1.initialize()\n",
    "    h2.initialize()\n",
    "    \n",
    "    cost = CategoricalCrossEntropy().apply(y, y_hat)\n",
    "    \n",
    "    cg = ComputationGraph(cost)\n",
    "    W1, W2 = VariableFilter(roles=[WEIGHT])(cg.variables)\n",
    "    \n",
    "    cost = cost + 0.005 * (W1 ** 2).sum() + 0.005 * (W2 ** 2).sum()\n",
    "    cost.name = 'cost_with_regularization'\n",
    "    \n",
    "    mcr = MisclassificationRate().apply(y.argmax(axis=1), y_hat)\n",
    "    mcr.name = \"misclassification rate\"\n",
    "    \n",
    "    return cg,(W1,W2),cost,mcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------\n",
      "BEFORE FIRST EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: True\n",
      "\t epochs_done: 0\n",
      "\t iterations_done: 0\n",
      "\t received_first_batch: False\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 0:\n",
      "\t cost_with_regularization: 0.69959283783\n",
      "\t misclassification rate: 0.515\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 1\n",
      "\t iterations_done: 130\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 130:\n",
      "\t cost_with_regularization: 0.620252515407\n",
      "\t misclassification rate: 0.1023\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 2\n",
      "\t iterations_done: 260\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 260:\n",
      "\t cost_with_regularization: 0.283540207938\n",
      "\t misclassification rate: 0.08\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 3\n",
      "\t iterations_done: 390\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 390:\n",
      "\t cost_with_regularization: 0.21732529216\n",
      "\t misclassification rate: 0.0275\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 4\n",
      "\t iterations_done: 520\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 520:\n",
      "\t cost_with_regularization: 0.200206408557\n",
      "\t misclassification rate: 0.0234\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 5\n",
      "\t iterations_done: 650\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 650:\n",
      "\t cost_with_regularization: 0.193827570941\n",
      "\t misclassification rate: 0.0224\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 6\n",
      "\t iterations_done: 780\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 780:\n",
      "\t cost_with_regularization: 0.190562662214\n",
      "\t misclassification rate: 0.0203\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 7\n",
      "\t iterations_done: 910\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 910:\n",
      "\t cost_with_regularization: 0.188616155387\n",
      "\t misclassification rate: 0.019\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 8\n",
      "\t iterations_done: 1040\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1040:\n",
      "\t cost_with_regularization: 0.187379148901\n",
      "\t misclassification rate: 0.0182\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 9\n",
      "\t iterations_done: 1170\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1170:\n",
      "\t cost_with_regularization: 0.186563359277\n",
      "\t misclassification rate: 0.0182\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 10\n",
      "\t iterations_done: 1300\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1300:\n",
      "\t cost_with_regularization: 0.186008641756\n",
      "\t misclassification rate: 0.0182\n",
      "\t training_finish_requested: True\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "TRAINING HAS BEEN FINISHED:\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 10\n",
      "\t iterations_done: 1300\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1300:\n",
      "\t cost_with_regularization: 0.186008641756\n",
      "\t misclassification rate: 0.0182\n",
      "\t training_finish_requested: True\n",
      "\t training_finished: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cg, (W1,W2), cost, mcr = makeGraph()\n",
    "\n",
    "main_loop = MainLoop(data_stream = data_stream, \n",
    "                     algorithm   = GradientDescent(\n",
    "                                    cost=cost, \n",
    "                                    parameters=cg.parameters,\n",
    "                                    step_rule=Scale(learning_rate=0.1)),\n",
    "                      extensions = [\n",
    "                        DataStreamMonitoring(variables=[cost, mcr], data_stream=data_stream_test), \n",
    "                        FinishAfter(after_n_epochs=10), \n",
    "                        Printing(),\n",
    "                        #TrainingDataMonitoring([cost,], after_batch=True),\n",
    "                      ]\n",
    ")\n",
    "main_loop.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADWCAYAAAByiFEYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfOgSQkghfOgSQkghfOgSQkgh/wfgOvKujI0WyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9d8383710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAAWCAYAAABjYE+sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA+RJREFUeJztnE1u2zAQhR+L7pwD+DaGzxRkbWlt+EyBb6MDOGt1UTBg\nJjPko6SoCfq+lU2T80uOLU7aNM8zhBBC7MOvf22AEEL8T6joCiHEjqjoCiHEjqjoCiHEjqjoCiHE\njvyufZhS0p82CCHEAuZ5Tt54tehmDocDXl5eAADPz894enrC4/HA7XbDMAwf5tr30fgwDLher3h7\ne/sgnxnL761t1+sVAKqyrP29YwDe33s+eWNZFoAP8kqYOTWsbdGc0idWp42jl+Mo73ZtpLPM3eVy\n+SRnHMdN82n30OPxoHVaInujWGSd5V5unQGPlk9RvNl5XhzZs9iKERvbmt+lrUx8ynVePHprTi1m\nKbn1FgBZdLMyAO9KSuM9Xl9fAQDn87kpt5TPjHmf2dfRfM/+3rFePBl2Q0R6vDh6BdazzX4JWZ8i\nnXadF8eI1tpIJyN7y3zW9k1LJwCcTifc7/eqvafTCQDe5/Xu6VZMGJ+8GLDzvDiyZ9H67sH6ac9A\ntIfsuaj5Ub5fWnNaey6CutM9HA7vr/MvAu+XQcn5fK4W3FJuKZ8Z8z7Lr1uyPPt7xlp+bw0TR4Cz\nzfrk+evhxZHFro102tyxdqzJ5xL7e7jf7x+KTu+ebulkfGJzzMpnbbO+e7Cy7BlgfWJzvqbmRDpr\npNq/SEspzdFjY4Z9vGDn/SRqj4vl2B7XC3tS+ghsn8/oMXBLbJ6maVqscw97GdacxaX7j9X5Hfb3\n1nmq+TQMQ3inu/qvF6ZpwjzPmOcZ0zStnveT8Hzyxo7HI1JKSCnheDy6spg534XSx6/IZxmLr4qH\nzdManXvYy7DmLC7df6zO77C/t87T7XbDOI4Yx7GreDfvdC+XS/Uinb3zZO41a2PZyQwzj2kE9I4B\nn+9Iy9fsHVp092lfe9i10ZiNB9sEacUxuhtj1jI6o7v5LfNp89SjE/h7z5gfeaO1FrZZFem0MGfR\ni3fPHm01Ltnz78ln/Yz8Ln3K40DcSO/JMdN0bj3pRlCNtNpFegRzkb6mgcXMYxoBS8b2hIkjsKwR\nxfrW0yRorY10MrK3zucS+3tgGkDsGfBgfFqzf9nGpQfTSGdlMQ1Jj6UNSW+M/aJiYkwVXXuRnr89\narSKRJabv01aY+za1hzP/p6xJWRZpQx79+XNAfw4evdmnm3214P1KdJp13lxjGitjXQysrfMZ5bV\n0h35zjQ37RxPJ3sGPBifonhHssp5XhytbVEc2eYv46c9A5FP0Zny9nu5lskBG1urw6PZSKuuFkII\n4RI10qpFVwghxLbo/14QQogdUdEVQogdUdEVQogdUdEVQogdUdEVQogd+QND2ad2z8tueQAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9caa11290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def hinton(matrix, max_weight=None, ax=None):\n",
    "    \"\"\"Draw Hinton diagram for visualizing a weight matrix.\"\"\"\n",
    "    ax = ax if ax is not None else plt.gca()\n",
    "\n",
    "    if not max_weight:\n",
    "        max_weight = 2**np.ceil(np.log(np.abs(matrix).max())/np.log(2))\n",
    "\n",
    "    ax.patch.set_facecolor('gray')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "    for (x, y), w in np.ndenumerate(matrix):\n",
    "        color = 'white' if w > 0 else 'black'\n",
    "        size = np.sqrt(np.abs(w))\n",
    "        rect = plt.Rectangle([x - size / 2, y - size / 2], size, size,\n",
    "                             facecolor=color, edgecolor=color)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.autoscale_view()\n",
    "    ax.invert_yaxis()\n",
    "#print W1.get_value()\n",
    "hinton(W1.get_value())\n",
    "plt.show()\n",
    "hinton(W2.get_value())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------\n",
      "BEFORE FIRST EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: True\n",
      "\t epochs_done: 0\n",
      "\t iterations_done: 0\n",
      "\t received_first_batch: False\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 0:\n",
      "\t cost_with_regularization: 0.702552455124\n",
      "\t misclassification rate: 0.515\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 1\n",
      "\t iterations_done: 130\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 130:\n",
      "\t cost_with_regularization: 0.640689906044\n",
      "\t misclassification rate: 0.1123\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 2\n",
      "\t iterations_done: 260\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 260:\n",
      "\t cost_with_regularization: 0.565039684348\n",
      "\t misclassification rate: 0.1116\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 3\n",
      "\t iterations_done: 390\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 390:\n",
      "\t cost_with_regularization: 0.502925224399\n",
      "\t misclassification rate: 0.1126\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 4\n",
      "\t iterations_done: 520\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 520:\n",
      "\t cost_with_regularization: 0.458707586839\n",
      "\t misclassification rate: 0.1085\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 5\n",
      "\t iterations_done: 650\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 650:\n",
      "\t cost_with_regularization: 0.426959709602\n",
      "\t misclassification rate: 0.103\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 6\n",
      "\t iterations_done: 780\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 780:\n",
      "\t cost_with_regularization: 0.403076199155\n",
      "\t misclassification rate: 0.0994\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 7\n",
      "\t iterations_done: 910\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 910:\n",
      "\t cost_with_regularization: 0.384273697757\n",
      "\t misclassification rate: 0.0933\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 8\n",
      "\t iterations_done: 1040\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1040:\n",
      "\t cost_with_regularization: 0.368939790471\n",
      "\t misclassification rate: 0.0858\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 9\n",
      "\t iterations_done: 1170\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1170:\n",
      "\t cost_with_regularization: 0.356105551651\n",
      "\t misclassification rate: 0.0786\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 10\n",
      "\t iterations_done: 1300\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1300:\n",
      "\t cost_with_regularization: 0.345154057569\n",
      "\t misclassification rate: 0.0713\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 11\n",
      "\t iterations_done: 1430\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1430:\n",
      "\t cost_with_regularization: 0.335669374797\n",
      "\t misclassification rate: 0.0626\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 12\n",
      "\t iterations_done: 1560\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1560:\n",
      "\t cost_with_regularization: 0.32735705967\n",
      "\t misclassification rate: 0.0581\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 13\n",
      "\t iterations_done: 1690\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1690:\n",
      "\t cost_with_regularization: 0.320000392575\n",
      "\t misclassification rate: 0.0501\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 14\n",
      "\t iterations_done: 1820\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1820:\n",
      "\t cost_with_regularization: 0.313434946638\n",
      "\t misclassification rate: 0.0486\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 15\n",
      "\t iterations_done: 1950\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1950:\n",
      "\t cost_with_regularization: 0.307532986165\n",
      "\t misclassification rate: 0.0437\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 16\n",
      "\t iterations_done: 2080\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2080:\n",
      "\t cost_with_regularization: 0.302193406938\n",
      "\t misclassification rate: 0.0409\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 17\n",
      "\t iterations_done: 2210\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2210:\n",
      "\t cost_with_regularization: 0.29733496368\n",
      "\t misclassification rate: 0.0367\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 18\n",
      "\t iterations_done: 2340\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2340:\n",
      "\t cost_with_regularization: 0.292891542772\n",
      "\t misclassification rate: 0.0347\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 19\n",
      "\t iterations_done: 2470\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2470:\n",
      "\t cost_with_regularization: 0.288808763333\n",
      "\t misclassification rate: 0.0324\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 20\n",
      "\t iterations_done: 2600\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2600:\n",
      "\t cost_with_regularization: 0.285041473737\n",
      "\t misclassification rate: 0.0316\n",
      "\t training_finish_requested: True\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "TRAINING HAS BEEN FINISHED:\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 20\n",
      "\t iterations_done: 2600\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2600:\n",
      "\t cost_with_regularization: 0.285041473737\n",
      "\t misclassification rate: 0.0316\n",
      "\t training_finish_requested: True\n",
      "\t training_finished: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cg, (W1,W2), cost, mcr = makeGraph()\n",
    "main_loop = MainLoop(data_stream = data_stream, \n",
    "                     algorithm   = GradientDescent(\n",
    "                                        cost=cost, \n",
    "                                        parameters=cg.parameters,\n",
    "                                        step_rule=AdaGrad()),\n",
    "                    extensions = [\n",
    "                        DataStreamMonitoring(variables=[cost, mcr], data_stream=data_stream_test), \n",
    "                        FinishAfter(after_n_epochs=20), \n",
    "                        Printing(),\n",
    "                        #TrainingDataMonitoring([cost,], after_batch=True),\n",
    "                      ]\n",
    ")\n",
    "main_loop.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------\n",
      "BEFORE FIRST EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: True\n",
      "\t epochs_done: 0\n",
      "\t iterations_done: 0\n",
      "\t received_first_batch: False\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 0:\n",
      "\t cost_with_regularization: 0.6988425957\n",
      "\t misclassification rate: 0.515\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 1\n",
      "\t iterations_done: 130\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 130:\n",
      "\t cost_with_regularization: 0.262812283985\n",
      "\t misclassification rate: 0.0239\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 2\n",
      "\t iterations_done: 260\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 260:\n",
      "\t cost_with_regularization: 0.209310776135\n",
      "\t misclassification rate: 0.0198\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 3\n",
      "\t iterations_done: 390\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 390:\n",
      "\t cost_with_regularization: 0.193854598557\n",
      "\t misclassification rate: 0.0185\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 4\n",
      "\t iterations_done: 520\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 520:\n",
      "\t cost_with_regularization: 0.188016365901\n",
      "\t misclassification rate: 0.0185\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 5\n",
      "\t iterations_done: 650\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 650:\n",
      "\t cost_with_regularization: 0.18565258418\n",
      "\t misclassification rate: 0.0185\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 6\n",
      "\t iterations_done: 780\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 780:\n",
      "\t cost_with_regularization: 0.184669017289\n",
      "\t misclassification rate: 0.0169\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 7\n",
      "\t iterations_done: 910\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 910:\n",
      "\t cost_with_regularization: 0.184248923454\n",
      "\t misclassification rate: 0.0169\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 8\n",
      "\t iterations_done: 1040\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1040:\n",
      "\t cost_with_regularization: 0.184060206661\n",
      "\t misclassification rate: 0.0169\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 9\n",
      "\t iterations_done: 1170\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1170:\n",
      "\t cost_with_regularization: 0.183967429941\n",
      "\t misclassification rate: 0.0169\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 10\n",
      "\t iterations_done: 1300\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1300:\n",
      "\t cost_with_regularization: 0.183915845187\n",
      "\t misclassification rate: 0.0169\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 11\n",
      "\t iterations_done: 1430\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1430:\n",
      "\t cost_with_regularization: 0.183883338829\n",
      "\t misclassification rate: 0.0169\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 12\n",
      "\t iterations_done: 1560\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1560:\n",
      "\t cost_with_regularization: 0.183860739376\n",
      "\t misclassification rate: 0.0169\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 13\n",
      "\t iterations_done: 1690\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1690:\n",
      "\t cost_with_regularization: 0.183843969465\n",
      "\t misclassification rate: 0.0164\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 14\n",
      "\t iterations_done: 1820\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1820:\n",
      "\t cost_with_regularization: 0.183831003202\n",
      "\t misclassification rate: 0.0164\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 15\n",
      "\t iterations_done: 1950\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1950:\n",
      "\t cost_with_regularization: 0.183820699407\n",
      "\t misclassification rate: 0.0164\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 16\n",
      "\t iterations_done: 2080\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2080:\n",
      "\t cost_with_regularization: 0.18381234366\n",
      "\t misclassification rate: 0.0164\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 17\n",
      "\t iterations_done: 2210\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2210:\n",
      "\t cost_with_regularization: 0.183805455166\n",
      "\t misclassification rate: 0.0164\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 18\n",
      "\t iterations_done: 2340\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2340:\n",
      "\t cost_with_regularization: 0.183799695302\n",
      "\t misclassification rate: 0.0164\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 19\n",
      "\t iterations_done: 2470\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2470:\n",
      "\t cost_with_regularization: 0.183794818421\n",
      "\t misclassification rate: 0.0164\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 20\n",
      "\t iterations_done: 2600\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2600:\n",
      "\t cost_with_regularization: 0.183790642493\n",
      "\t misclassification rate: 0.0164\n",
      "\t training_finish_requested: True\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "TRAINING HAS BEEN FINISHED:\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 20\n",
      "\t iterations_done: 2600\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2600:\n",
      "\t cost_with_regularization: 0.183790642493\n",
      "\t misclassification rate: 0.0164\n",
      "\t training_finish_requested: True\n",
      "\t training_finished: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cg, (W1,W2), cost, mcr = makeGraph()\n",
    "main_loop = MainLoop(data_stream = data_stream, \n",
    "                     algorithm   = GradientDescent(\n",
    "                                        cost=cost, \n",
    "                                        parameters=cg.parameters,\n",
    "                                        step_rule=Adam()),\n",
    "                      extensions = [\n",
    "                        DataStreamMonitoring(variables=[cost, mcr], data_stream=data_stream_test), \n",
    "                        FinishAfter(after_n_epochs=20), \n",
    "                        Printing(),\n",
    "                        #TrainingDataMonitoring([cost,], after_batch=True),\n",
    "                      ]\n",
    ")\n",
    "main_loop.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
