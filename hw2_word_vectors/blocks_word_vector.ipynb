{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "from theano import tensor\n",
    "\n",
    "import fuel\n",
    "import h5py\n",
    "from fuel.datasets.hdf5 import H5PYDataset\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme\n",
    "from fuel.transformers import Flatten\n",
    "from fuel.datasets.text import TextFile\n",
    "\n",
    "from blocks.bricks import Linear, Logistic, Softmax\n",
    "from blocks.bricks.cost import CategoricalCrossEntropy\n",
    "from blocks.roles import WEIGHT\n",
    "from blocks.graph import ComputationGraph\n",
    "from blocks.filter import VariableFilter\n",
    "from blocks.initialization import IsotropicGaussian, Constant\n",
    "from blocks.algorithms import GradientDescent, Scale, AdaGrad, Adam\n",
    "from blocks.extensions.monitoring import DataStreamMonitoring\n",
    "from blocks.main_loop import MainLoop\n",
    "from blocks.extensions import FinishAfter, Printing\n",
    "from blocks.extensions.monitoring import TrainingDataMonitoring\n",
    "from blocks_extras.extensions.plot import Plot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"./data/text8.zip\"\n",
    "\n",
    "def read_data(filename):\n",
    "  f = zipfile.ZipFile(filename)\n",
    "  for name in f.namelist():\n",
    "    return f.read(name).split()\n",
    "  f.close()\n",
    "  \n",
    "#words = read_data(filename)\n",
    "#print 'Data size', len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-96e939baa811>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-96e939baa811>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    data =\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from fuel.datasets.base import Dataset\n",
    "\n",
    "class WordWindow(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.provides_sources = ('features', 'targets')\n",
    "         # for technical reasons\n",
    "        self.axis_labels = None\n",
    "        with self.open() as fh:\n",
    "            self.corpus = fh.read().split(\" \")\n",
    "        \n",
    "        super(WordWindow, self).__init__(**kwargs)\n",
    "    \n",
    "    def get_data(self, state=None, request=None):\n",
    "        data = \n",
    "        return self.filter_sources(data)\n",
    "\n",
    "    def open(self):\n",
    "        return open('./data/small')\n",
    "    \n",
    "    def close(self,fh):\n",
    "        fh.close()\n",
    "    \n",
    "dataset = WordWindow().get_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'</S>': 1, '<UNK>': 0}\n",
      "([0, 0, 0, 0, 0, 1],)\n",
      "([0, 0, 0, 0, 0, 1],)\n",
      "([0, 0, 0, 0, 0, 1],)\n",
      "([0, 0, 0, 0, 0, 1],)\n",
      "([0, 0, 0, 0, 0, 1],)\n",
      "([0, 0, 0, 0, 0, 1],)\n"
     ]
    }
   ],
   "source": [
    "from fuel.streams import DataStream\n",
    "print dictionary\n",
    "for data in DataStream(text_data).get_epoch_iterator():\n",
    "    print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_stream = DataStream(text_data,\n",
    "     iteration_scheme=SequentialScheme(train_data.num_examples, batch_size=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeGraph():\n",
    "    Xs = tensor.matrix(\"features\")\n",
    "    y = tensor.lmatrix('targets')\n",
    "    \n",
    "    h1 = Linear(name='h1', input_dim=117, output_dim=70)\n",
    "    a1 = Logistic().apply(h1.apply(Xs))\n",
    "    h2 = Linear(name='h2', input_dim=70, output_dim=2)\n",
    "    y_hat = Softmax().apply(h2.apply(a1))\n",
    "    \n",
    "    h1.weights_init = h2.weights_init = IsotropicGaussian(0.01)\n",
    "    h1.biases_init = h2.biases_init = Constant(0)\n",
    "    h1.initialize()\n",
    "    h2.initialize()\n",
    "    \n",
    "    cost = CategoricalCrossEntropy().apply(y, y_hat)\n",
    "    \n",
    "    cg = ComputationGraph(cost)\n",
    "    W1, W2 = VariableFilter(roles=[WEIGHT])(cg.variables)\n",
    "    \n",
    "    cost = cost + 0.005 * (W1 ** 2).sum() + 0.005 * (W2 ** 2).sum()\n",
    "    cost.name = 'cost_with_regularization'\n",
    "    \n",
    "    mcr = MisclassificationRate().apply(y.argmax(axis=1), y_hat)\n",
    "    mcr.name = \"misclassification rate\"\n",
    "    \n",
    "    return cg,(W1,W2),cost,mcr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
